{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain = pd.read_csv(\"CWRU Dataset-1-train.csv\")\n",
    "#Dtrain = Dtrain.iloc[:,0:4].values\n",
    "Dtest = pd.read_csv(\"CWRU Dataset-1-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inner Race (0.007\")    96896\n",
       "Normal                 96896\n",
       "Outer Race (0.007\")    96896\n",
       "Name: Bearing, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtrain[\"Bearing\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inner Race (0.007\")    33.333333\n",
       "Normal                 33.333333\n",
       "Outer Race (0.007\")    33.333333\n",
       "Name: Bearing, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtrain[\"Bearing\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bearing', 'Fault Diameter', 'DE', 'FE'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_train = LabelEncoder()\n",
    "Dtrain[\"Bearing\"] = labelencoder_train.fit_transform(Dtrain[\"Bearing\"])\n",
    "ct = ColumnTransformer([(\"Bearing\", OneHotEncoder(), [0])],    remainder = 'passthrough')\n",
    "Dtrain = ct.fit_transform(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_train = LabelEncoder()\n",
    "Dtest[\"Bearing\"] = labelencoder_train.fit_transform(Dtest[\"Bearing\"])\n",
    "ct = ColumnTransformer([(\"Bearing\", OneHotEncoder(), [0])],    remainder = 'passthrough')\n",
    "Dtest = ct.fit_transform(Dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(Dtrain))\n",
    "# Random shuffle training data\n",
    "X_train.sample(frac=1)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(Dtest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.core import Dense \n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "tf.random.set_seed(10)\n",
    "act_func = 'elu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer:\n",
    "model=Sequential()\n",
    "# First hidden layer, connected to input vector X. \n",
    "model.add(Dense(6,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_shape=(X_train.shape[1],)\n",
    "               )\n",
    "         )\n",
    "\n",
    "model.add(Dense(3,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam', metrics=['accuracy'] )\n",
    "\n",
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=100\n",
    "BATCH_SIZE=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 276153 samples, validate on 14535 samples\n",
      "Epoch 1/100\n",
      "276153/276153 [==============================] - 3s 11us/step - loss: 0.0184 - accuracy: 0.6063 - val_loss: 0.0033 - val_accuracy: 0.4350\n",
      "Epoch 2/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 0.0017 - accuracy: 0.6818 - val_loss: 0.0020 - val_accuracy: 0.5395\n",
      "Epoch 3/100\n",
      "276153/276153 [==============================] - 3s 12us/step - loss: 6.5187e-04 - accuracy: 0.6774 - val_loss: 5.9950e-04 - val_accuracy: 0.4440\n",
      "Epoch 4/100\n",
      "276153/276153 [==============================] - 4s 13us/step - loss: 1.5600e-04 - accuracy: 0.6781 - val_loss: 6.9300e-05 - val_accuracy: 0.6395\n",
      "Epoch 5/100\n",
      "276153/276153 [==============================] - 4s 13us/step - loss: 6.0147e-05 - accuracy: 0.6746 - val_loss: 3.3831e-05 - val_accuracy: 0.5615\n",
      "Epoch 6/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 3.9206e-05 - accuracy: 0.6699 - val_loss: 2.6332e-05 - val_accuracy: 0.6405\n",
      "Epoch 7/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 2.8310e-05 - accuracy: 0.6680 - val_loss: 2.0675e-05 - val_accuracy: 0.4118\n",
      "Epoch 8/100\n",
      "276153/276153 [==============================] - 4s 13us/step - loss: 2.1951e-05 - accuracy: 0.6664 - val_loss: 1.6979e-05 - val_accuracy: 0.4308\n",
      "Epoch 9/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 1.7927e-05 - accuracy: 0.6651 - val_loss: 1.3272e-05 - val_accuracy: 0.4219\n",
      "Epoch 10/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 1.5075e-05 - accuracy: 0.6649 - val_loss: 1.2469e-05 - val_accuracy: 0.3443\n",
      "Epoch 11/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 1.2922e-05 - accuracy: 0.6650 - val_loss: 1.3792e-05 - val_accuracy: 0.4429\n",
      "Epoch 12/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 1.1071e-05 - accuracy: 0.6631 - val_loss: 8.5548e-06 - val_accuracy: 0.5628\n",
      "Epoch 13/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 9.7349e-06 - accuracy: 0.6627 - val_loss: 8.6242e-06 - val_accuracy: 0.2836\n",
      "Epoch 14/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 8.4276e-06 - accuracy: 0.6615 - val_loss: 7.2008e-06 - val_accuracy: 0.6811\n",
      "Epoch 15/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 7.3438e-06 - accuracy: 0.6613 - val_loss: 6.8381e-06 - val_accuracy: 0.2830\n",
      "Epoch 16/100\n",
      "276153/276153 [==============================] - 4s 13us/step - loss: 6.3199e-06 - accuracy: 0.6594 - val_loss: 5.2669e-06 - val_accuracy: 0.3166\n",
      "Epoch 17/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 5.5339e-06 - accuracy: 0.6589 - val_loss: 4.3241e-06 - val_accuracy: 0.5033\n",
      "Epoch 18/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 4.6934e-06 - accuracy: 0.6565 - val_loss: 4.4086e-06 - val_accuracy: 0.7364\n",
      "Epoch 19/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 4.1054e-06 - accuracy: 0.6529 - val_loss: 4.5148e-06 - val_accuracy: 0.2542\n",
      "Epoch 20/100\n",
      "276153/276153 [==============================] - 4s 13us/step - loss: 3.6445e-06 - accuracy: 0.6497 - val_loss: 3.2544e-06 - val_accuracy: 0.3347\n",
      "Epoch 21/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 3.4095e-06 - accuracy: 0.6452 - val_loss: 3.2388e-06 - val_accuracy: 0.3016\n",
      "Epoch 22/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 3.0826e-06 - accuracy: 0.6398 - val_loss: 2.7443e-06 - val_accuracy: 0.1568\n",
      "Epoch 23/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 2.9069e-06 - accuracy: 0.6422 - val_loss: 2.9453e-06 - val_accuracy: 0.4331\n",
      "Epoch 24/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 2.8386e-06 - accuracy: 0.6413 - val_loss: 2.5601e-06 - val_accuracy: 0.1811\n",
      "Epoch 25/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 2.6080e-06 - accuracy: 0.6411 - val_loss: 2.1178e-06 - val_accuracy: 0.3583\n",
      "Epoch 26/100\n",
      "276153/276153 [==============================] - 4s 14us/step - loss: 2.5295e-06 - accuracy: 0.6407 - val_loss: 2.7896e-06 - val_accuracy: 0.5494\n",
      "Epoch 27/100\n",
      "164800/276153 [================>.............] - ETA: 1s - loss: 2.4609e-06 - accuracy: 0.6422"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(X_train),np.array(X_train),\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.05,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], 'b', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss, [mse]')\n",
    "plt.ylim([0,.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_train))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "scored = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "plt.figure()\n",
    "sns.distplot(scored, bins = 10, kde= True, color = 'blue');\n",
    "plt.xlim([0.0,.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_test))\n",
    "\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = 0.0025\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = model.predict(np.array(X_train))\n",
    "X_pred_train = pd.DataFrame(X_pred_train)\n",
    "\n",
    "scored_train = pd.DataFrame()\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = 0.0025\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.plot(logy=True,  figsize = (10,6), xlim =[0,1000], ylim = [1e-4,1e-1], color = ['blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_train['Loss_mae'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
