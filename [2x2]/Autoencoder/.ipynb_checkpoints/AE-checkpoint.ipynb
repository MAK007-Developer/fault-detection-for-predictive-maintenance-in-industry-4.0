{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain = pd.read_csv(\"TrainingSet (IR - 7).csv\")\n",
    "#Dtrain = Dtrain.iloc[:,0:4].values\n",
    "Dtest = pd.read_csv(\"TestingSet (IR - 7).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal                 96896\n",
       "Inner Race (0.007\")    96896\n",
       "Name: Bearing, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtrain[\"Bearing\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal                 50.0\n",
       "Inner Race (0.007\")    50.0\n",
       "Name: Bearing, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtrain[\"Bearing\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bearing', 'Fault Diameter', 'DE', 'FE'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_train = LabelEncoder()\n",
    "Dtrain[\"Bearing\"] = labelencoder_train.fit_transform(Dtrain[\"Bearing\"])\n",
    "ct = ColumnTransformer([(\"Bearing\", OneHotEncoder(), [0])],    remainder = 'passthrough')\n",
    "Dtrain = ct.fit_transform(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_train = LabelEncoder()\n",
    "Dtest[\"Bearing\"] = labelencoder_train.fit_transform(Dtest[\"Bearing\"])\n",
    "ct = ColumnTransformer([(\"Bearing\", OneHotEncoder(), [0])],    remainder = 'passthrough')\n",
    "Dtest = ct.fit_transform(Dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(Dtrain))\n",
    "# Random shuffle training data\n",
    "X_train.sample(frac=1)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(Dtest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.core import Dense \n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "tf.random.set_seed(10)\n",
    "act_func = 'elu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer:\n",
    "model=Sequential()\n",
    "# First hidden layer, connected to input vector X. \n",
    "model.add(Dense(6,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_shape=(X_train.shape[1],)\n",
    "               )\n",
    "         )\n",
    "\n",
    "model.add(Dense(2,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam', metrics=['accuracy'] )\n",
    "\n",
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=100\n",
    "BATCH_SIZE=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 184102 samples, validate on 9690 samples\n",
      "Epoch 1/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 0.0212 - accuracy: 0.7868 - val_loss: 0.0041 - val_accuracy: 0.4711\n",
      "Epoch 2/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 0.0014 - accuracy: 0.7641 - val_loss: 0.0020 - val_accuracy: 0.5270\n",
      "Epoch 3/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 9.9439e-04 - accuracy: 0.8037 - val_loss: 0.0020 - val_accuracy: 0.6747\n",
      "Epoch 4/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 9.7114e-04 - accuracy: 0.8511 - val_loss: 0.0019 - val_accuracy: 0.5197\n",
      "Epoch 5/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 9.6016e-04 - accuracy: 0.8380 - val_loss: 0.0020 - val_accuracy: 0.4740\n",
      "Epoch 6/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 9.5322e-04 - accuracy: 0.8267 - val_loss: 0.0019 - val_accuracy: 0.8186\n",
      "Epoch 7/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 9.4552e-04 - accuracy: 0.8258 - val_loss: 0.0019 - val_accuracy: 0.1778\n",
      "Epoch 8/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 9.2948e-04 - accuracy: 0.8160 - val_loss: 0.0019 - val_accuracy: 0.6833\n",
      "Epoch 9/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 7.1219e-04 - accuracy: 0.7793 - val_loss: 3.0813e-04 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 1.3314e-04 - accuracy: 0.7696 - val_loss: 4.2861e-05 - val_accuracy: 0.6814\n",
      "Epoch 11/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 5.7889e-05 - accuracy: 0.8178 - val_loss: 5.6917e-05 - val_accuracy: 0.7759\n",
      "Epoch 12/100\n",
      "184102/184102 [==============================] - 3s 17us/step - loss: 4.1042e-05 - accuracy: 0.8239 - val_loss: 2.2842e-05 - val_accuracy: 0.5485\n",
      "Epoch 13/100\n",
      "184102/184102 [==============================] - 3s 17us/step - loss: 3.6206e-05 - accuracy: 0.8278 - val_loss: 3.0054e-05 - val_accuracy: 0.2772\n",
      "Epoch 14/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 3.3434e-05 - accuracy: 0.8277 - val_loss: 5.3531e-05 - val_accuracy: 0.7092\n",
      "Epoch 15/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 3.0932e-05 - accuracy: 0.8205 - val_loss: 1.9150e-05 - val_accuracy: 0.7254\n",
      "Epoch 16/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 2.8622e-05 - accuracy: 0.8217 - val_loss: 1.9065e-05 - val_accuracy: 0.6530\n",
      "Epoch 17/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 2.6588e-05 - accuracy: 0.8220 - val_loss: 1.5422e-05 - val_accuracy: 0.0702\n",
      "Epoch 18/100\n",
      "184102/184102 [==============================] - 3s 15us/step - loss: 2.4852e-05 - accuracy: 0.8171 - val_loss: 1.9572e-05 - val_accuracy: 0.1028\n",
      "Epoch 19/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 2.3365e-05 - accuracy: 0.8150 - val_loss: 2.1120e-05 - val_accuracy: 0.8227\n",
      "Epoch 20/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 2.2027e-05 - accuracy: 0.8157 - val_loss: 1.1671e-05 - val_accuracy: 0.8474\n",
      "Epoch 21/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 2.0551e-05 - accuracy: 0.8152 - val_loss: 1.5949e-05 - val_accuracy: 0.8197\n",
      "Epoch 22/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 1.9603e-05 - accuracy: 0.8159 - val_loss: 5.2038e-05 - val_accuracy: 0.8275\n",
      "Epoch 23/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 1.8589e-05 - accuracy: 0.8158 - val_loss: 1.2401e-05 - val_accuracy: 0.8380\n",
      "Epoch 24/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 1.7613e-05 - accuracy: 0.8152 - val_loss: 9.6815e-06 - val_accuracy: 0.6360\n",
      "Epoch 25/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 1.6878e-05 - accuracy: 0.8073 - val_loss: 9.1614e-06 - val_accuracy: 0.0277\n",
      "Epoch 26/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 1.5896e-05 - accuracy: 0.8070 - val_loss: 1.5446e-05 - val_accuracy: 0.3121\n",
      "Epoch 27/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 1.5461e-05 - accuracy: 0.8008 - val_loss: 1.2670e-05 - val_accuracy: 0.7548\n",
      "Epoch 28/100\n",
      "184102/184102 [==============================] - 2s 13us/step - loss: 1.4747e-05 - accuracy: 0.8045 - val_loss: 1.3087e-05 - val_accuracy: 0.7110\n",
      "Epoch 29/100\n",
      "184102/184102 [==============================] - 3s 14us/step - loss: 1.4260e-05 - accuracy: 0.8027 - val_loss: 7.6372e-06 - val_accuracy: 0.7014\n",
      "Epoch 30/100\n",
      " 15500/184102 [=>............................] - ETA: 2s - loss: 1.4438e-05 - accuracy: 0.8001"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(X_train),np.array(X_train),\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.05,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], 'b', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss, [mse]')\n",
    "plt.ylim([0,.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_train))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "scored = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "plt.figure()\n",
    "sns.distplot(scored, bins = 10, kde= True, color = 'blue');\n",
    "plt.xlim([0.0,.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_test))\n",
    "\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = 0.006\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = model.predict(np.array(X_train))\n",
    "X_pred_train = pd.DataFrame(X_pred_train)\n",
    "\n",
    "scored_train = pd.DataFrame()\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = 0.006\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_train['Loss_mae'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.plot(logy=True,  figsize = (10,6), xlim =[0,1000], ylim = [1e-4,1e-1], color = ['blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
